{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "import csv"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1681329944848
        }
      },
      "id": "80369be3"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-04-12 20:05:44.154242: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-04-12 20:05:45.023501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-04-12 20:05:45.023574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-04-12 20:05:45.023582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1681329946734
        }
      },
      "id": "ff820743"
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1681329947301
        }
      },
      "id": "7e7516f8"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Python version:', platform.python_version())\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('Keras version:', tf.keras.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Python version: 3.8.5\nTensorflow version: 2.11.0\nKeras version: 2.11.0\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1681329947893
        }
      },
      "id": "cda717c4"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(csv_file_path, silent=False):\n",
        "    dataset = []\n",
        "\n",
        "    with open(csv_file_path, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            dataset.append(row)\n",
        "\n",
        "        if silent == False:\n",
        "            print(csv_file_path)\n",
        "            print('===========================================')\n",
        "            print('Number of examples: ', len(dataset), '\\n')\n",
        "            print('Example object keys:\\n', dataset[0].keys(), '\\n')\n",
        "            print('Example object:\\n', dataset[0], '\\n')\n",
        "            print('Required keys:\\n')\n",
        "            print('  title: ', dataset[0]['Title'], '\\n')\n",
        "            print('  ingredients: ', dataset[0]['Ingredients'], '\\n')\n",
        "            print('  totaltime: ', dataset[0]['TotalTimeInMins'], '\\n')\n",
        "            print('  cusine: ', dataset[0]['Cuisine'], '\\n')\n",
        "            print('  instructions: ', dataset[0]['Instructions'],'\\n')\n",
        "            print('  url: ', dataset[0]['URL'], '\\n')\n",
        "            print('  cleanedingredients: ', dataset[0]['Cleaned-Ingredients'], '\\n')\n",
        "            print('  imageurl: ', dataset[0]['image-url'], '\\n')\n",
        "            print('  ingredientcount: ', dataset[0]['Ingredient-count'])\n",
        "            print('\\n\\n')\n",
        "\n",
        "    return dataset"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1681329948463
        }
      },
      "id": "6171f34e"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_raw = load_dataset('Cleaned_Indian_Food_Dataset.csv')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Cleaned_Indian_Food_Dataset.csv\n===========================================\nNumber of examples:  5938 \n\nExample object keys:\n dict_keys(['Title', 'Ingredients', 'TotalTimeInMins', 'Cuisine', 'Instructions', 'URL', 'Cleaned-Ingredients', 'image-url', 'Ingredient-count']) \n\nExample object:\n {'Title': 'Masala Karela Recipe', 'Ingredients': '1 tablespoon Red Chilli powder,3 tablespoon Gram flour (besan),2 teaspoons Cumin seeds (Jeera),1 tablespoon Coriander Powder (Dhania),2 teaspoons Turmeric powder (Haldi),Salt - to taste,1 tablespoon Amchur (Dry Mango Powder),6 Karela (Bitter Gourd/ Pavakkai) - deseeded,Sunflower Oil - as required,1 Onion - thinly sliced', 'TotalTimeInMins': '45', 'Cuisine': 'Indian', 'Instructions': 'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n', 'URL': 'https://www.archanaskitchen.com/masala-karela-recipe', 'Cleaned-Ingredients': 'salt,amchur (dry mango powder),karela (bitter gourd pavakkai),red chilli powder,gram flour (besan),onion,cumin seeds (jeera),coriander powder,turmeric powder,sunflower oil', 'image-url': 'https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Pooja_Thakur/Karela_Masala_Recipe-4_1600.jpg', 'Ingredient-count': '10'} \n\nRequired keys:\n\n  title:  Masala Karela Recipe \n\n  ingredients:  1 tablespoon Red Chilli powder,3 tablespoon Gram flour (besan),2 teaspoons Cumin seeds (Jeera),1 tablespoon Coriander Powder (Dhania),2 teaspoons Turmeric powder (Haldi),Salt - to taste,1 tablespoon Amchur (Dry Mango Powder),6 Karela (Bitter Gourd/ Pavakkai) - deseeded,Sunflower Oil - as required,1 Onion - thinly sliced \n\n  totaltime:  45 \n\n  cusine:  Indian \n\n  instructions:  To begin making the Masala Karela Recipe,de-seed the karela and slice.\nDo not remove the skin as the skin has all the nutrients.\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\nRelease the pressure immediately and open the lids.\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\n \n\n  url:  https://www.archanaskitchen.com/masala-karela-recipe \n\n  cleanedingredients:  salt,amchur (dry mango powder),karela (bitter gourd pavakkai),red chilli powder,gram flour (besan),onion,cumin seeds (jeera),coriander powder,turmeric powder,sunflower oil \n\n  imageurl:  https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Pooja_Thakur/Karela_Masala_Recipe-4_1600.jpg \n\n  ingredientcount:  10\n\n\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1681329949384
        }
      },
      "id": "38b09900"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total number of raw examples: ', len(dataset_raw))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Total number of raw examples:  5938\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1681329950349
        }
      },
      "id": "7ef146f8"
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe_validate_required_fields(recipe):\n",
        "    required_keys = ['Title', 'Ingredients', 'TotalTimeInMins','Cuisine','Instructions','URL','Cleaned-Ingredients','image-url','Ingredient-count']\n",
        "    \n",
        "    if not recipe:\n",
        "        return False\n",
        "    \n",
        "    for required_key in required_keys:\n",
        "        if not recipe[required_key]:\n",
        "            return False\n",
        "        \n",
        "        if type(recipe[required_key]) == list and len(recipe[required_key]) == 0:\n",
        "            return False\n",
        "    \n",
        "    return True"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1681329951298
        }
      },
      "id": "d6ab9d42"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_validated = [recipe for recipe in dataset_raw if recipe_validate_required_fields(recipe)]\n",
        "\n",
        "print('Dataset size BEFORE validation', len(dataset_raw))\n",
        "print('Dataset size AFTER validation', len(dataset_validated))\n",
        "print('Number of incomplete recipes', len(dataset_raw) - len(dataset_validated))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset size BEFORE validation 5938\nDataset size AFTER validation 5938\nNumber of incomplete recipes 0\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1681329952676
        }
      },
      "id": "7413ba40"
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORD_TITLE = '📗 '\n",
        "STOP_WORD_INGREDIENTS = '\\n🥕\\n\\n'\n",
        "STOP_WORD_TOTALTIMEINMINS = '\\n⌛ '\n",
        "STOP_WORD_CUISINE = '\\n🍛 '\n",
        "STOP_WORD_INSTRUCTIONS = '\\n📝\\n\\n'\n",
        "STOP_WORD_URL = '\\n🌐 '\n",
        "STOP_WORD_CLEANEDINGREDIENTS = '\\n🍔\\n\\n'\n",
        "STOP_WORD_IMAGEURL = '\\n📷 '\n",
        "STOP_WORD_INGREDIENTCOUNT = '\\n🥗 '"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1681329954059
        }
      },
      "id": "4f974ae4"
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_validated[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Title': 'Masala Karela Recipe', 'Ingredients': '1 tablespoon Red Chilli powder,3 tablespoon Gram flour (besan),2 teaspoons Cumin seeds (Jeera),1 tablespoon Coriander Powder (Dhania),2 teaspoons Turmeric powder (Haldi),Salt - to taste,1 tablespoon Amchur (Dry Mango Powder),6 Karela (Bitter Gourd/ Pavakkai) - deseeded,Sunflower Oil - as required,1 Onion - thinly sliced', 'TotalTimeInMins': '45', 'Cuisine': 'Indian', 'Instructions': 'To begin making the Masala Karela Recipe,de-seed the karela and slice.\\nDo not remove the skin as the skin has all the nutrients.\\nAdd the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\\nRelease the pressure immediately and open the lids.\\nKeep aside.Heat oil in a heavy bottomed pan or a kadhai.\\nAdd cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\\nStir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\\nCover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\\nTurn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\\n', 'URL': 'https://www.archanaskitchen.com/masala-karela-recipe', 'Cleaned-Ingredients': 'salt,amchur (dry mango powder),karela (bitter gourd pavakkai),red chilli powder,gram flour (besan),onion,cumin seeds (jeera),coriander powder,turmeric powder,sunflower oil', 'image-url': 'https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Pooja_Thakur/Karela_Masala_Recipe-4_1600.jpg', 'Ingredient-count': '10'}\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1681329955602
        }
      },
      "id": "408a3541"
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe_to_string(recipe):\n",
        "    # This string is presented as a part of recipes so we need to clean it up.\n",
        "    noize_string = 'ADVERTISEMENT'\n",
        "    \n",
        "    title = recipe['Title']\n",
        "    ingredients = recipe['Ingredients'].split(',')\n",
        "    totaltimeinmins = recipe['TotalTimeInMins']\n",
        "    cuisine = recipe['Cuisine']\n",
        "    instructions = recipe['Instructions'].split('\\n')\n",
        "    url = recipe['URL']\n",
        "    cleanedingredients = recipe['Cleaned-Ingredients'].split(',')\n",
        "    imageurl = recipe['image-url']\n",
        "    ingredientcount = recipe['Ingredient-count']\n",
        "    \n",
        "    ingredients_string = ''\n",
        "    for ingredient in ingredients:\n",
        "        ingredient = ingredient.replace(noize_string, '')\n",
        "        if ingredient:\n",
        "            ingredients_string += f'• {ingredient}\\n'    # adding bullets to structure the data\n",
        "    \n",
        "    instructions_string = ''\n",
        "    for instruction in instructions:\n",
        "        instruction = instruction.replace(noize_string, '')\n",
        "        if instruction:\n",
        "            instructions_string += f'▪︎ {instruction}\\n'    # adding bullets to structure the data\n",
        "            \n",
        "    cleanedingredients_string = ''\n",
        "    for cleanedingredient in cleanedingredients:\n",
        "        cleanedingredient = cleanedingredient.replace(noize_string, '')\n",
        "        if cleanedingredient:\n",
        "            cleanedingredients_string += f'• {cleanedingredient}\\n'    # adding bullets to structure the data\n",
        "    \n",
        "    return f'{STOP_WORD_TITLE}{title}\\n{STOP_WORD_INGREDIENTS}{ingredients_string}{STOP_WORD_TOTALTIMEINMINS}{totaltimeinmins}\\n{STOP_WORD_CUISINE}{cuisine}\\n{STOP_WORD_INSTRUCTIONS}{instructions_string}{STOP_WORD_URL}{url}\\n{STOP_WORD_CLEANEDINGREDIENTS}{cleanedingredients_string}{STOP_WORD_IMAGEURL}{imageurl}\\n{STOP_WORD_INGREDIENTCOUNT}{ingredientcount}\\n'\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1681329956537
        }
      },
      "id": "ecf652ae"
    },
    {
      "cell_type": "code",
      "source": [
        "print(recipe_to_string(dataset_validated[0]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "📗 Masala Karela Recipe\n\n🥕\n\n• 1 tablespoon Red Chilli powder\n• 3 tablespoon Gram flour (besan)\n• 2 teaspoons Cumin seeds (Jeera)\n• 1 tablespoon Coriander Powder (Dhania)\n• 2 teaspoons Turmeric powder (Haldi)\n• Salt - to taste\n• 1 tablespoon Amchur (Dry Mango Powder)\n• 6 Karela (Bitter Gourd/ Pavakkai) - deseeded\n• Sunflower Oil - as required\n• 1 Onion - thinly sliced\n\n⌛ 45\n\n🍛 Indian\n\n📝\n\n▪︎ To begin making the Masala Karela Recipe,de-seed the karela and slice.\n▪︎ Do not remove the skin as the skin has all the nutrients.\n▪︎ Add the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\n▪︎ Release the pressure immediately and open the lids.\n▪︎ Keep aside.Heat oil in a heavy bottomed pan or a kadhai.\n▪︎ Add cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\n▪︎ Stir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\n▪︎ Cover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\n▪︎ Turn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\n\n🌐 https://www.archanaskitchen.com/masala-karela-recipe\n\n🍔\n\n• salt\n• amchur (dry mango powder)\n• karela (bitter gourd pavakkai)\n• red chilli powder\n• gram flour (besan)\n• onion\n• cumin seeds (jeera)\n• coriander powder\n• turmeric powder\n• sunflower oil\n\n📷 https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Pooja_Thakur/Karela_Masala_Recipe-4_1600.jpg\n\n🥗 10\n\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1681329957469
        }
      },
      "id": "860ee291"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_stringified = [recipe_to_string(recipe) for recipe in dataset_validated]\n",
        "print('Stringified dataset size: ', len(dataset_stringified))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Stringified dataset size:  5938\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1681329958645
        }
      },
      "id": "9546fd92"
    },
    {
      "cell_type": "code",
      "source": [
        "for recipe_index, recipe_string in enumerate(dataset_stringified[:3]):\n",
        "    print('Recipe #{}\\n---------'.format(recipe_index + 1))\n",
        "    print(recipe_string)\n",
        "    print('\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recipe #1\n---------\n📗 Masala Karela Recipe\n\n🥕\n\n• 1 tablespoon Red Chilli powder\n• 3 tablespoon Gram flour (besan)\n• 2 teaspoons Cumin seeds (Jeera)\n• 1 tablespoon Coriander Powder (Dhania)\n• 2 teaspoons Turmeric powder (Haldi)\n• Salt - to taste\n• 1 tablespoon Amchur (Dry Mango Powder)\n• 6 Karela (Bitter Gourd/ Pavakkai) - deseeded\n• Sunflower Oil - as required\n• 1 Onion - thinly sliced\n\n⌛ 45\n\n🍛 Indian\n\n📝\n\n▪︎ To begin making the Masala Karela Recipe,de-seed the karela and slice.\n▪︎ Do not remove the skin as the skin has all the nutrients.\n▪︎ Add the karela to the pressure cooker with 3 tablespoon of water, salt and turmeric powder and pressure cook for three whistles.\n▪︎ Release the pressure immediately and open the lids.\n▪︎ Keep aside.Heat oil in a heavy bottomed pan or a kadhai.\n▪︎ Add cumin seeds and let it sizzle.Once the cumin seeds have sizzled, add onions and saute them till it turns golden brown in color.Add the karela, red chilli powder, amchur powder, coriander powder and besan.\n▪︎ Stir to combine the masalas into the karela.Drizzle a little extra oil on the top and mix again.\n▪︎ Cover the pan and simmer Masala Karela stirring occasionally until everything comes together well.\n▪︎ Turn off the heat.Transfer Masala Karela into a serving bowl and serve.Serve Masala Karela along with Panchmel Dal and Phulka for a weekday meal with your family.\n\n🌐 https://www.archanaskitchen.com/masala-karela-recipe\n\n🍔\n\n• salt\n• amchur (dry mango powder)\n• karela (bitter gourd pavakkai)\n• red chilli powder\n• gram flour (besan)\n• onion\n• cumin seeds (jeera)\n• coriander powder\n• turmeric powder\n• sunflower oil\n\n📷 https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Pooja_Thakur/Karela_Masala_Recipe-4_1600.jpg\n\n🥗 10\n\n\n\nRecipe #2\n---------\n📗 Spicy Tomato Rice (Recipe)\n\n🥕\n\n•  2 teaspoon cashew - or peanuts\n•  1/2 Teaspoon mustard\n•  1 dry red chilli\n•  1 teaspoon white urad dal\n•  1 teaspoon chickpea lentils\n•  salt - as per taste\n•  1 green chilli\n•  1-1 / 2 tablespoon oil - 1/2 teaspoon asafoetida\n•  1/2 teaspoon cumin seeds\n•  3 teaspoons BC Belle Bhat powder\n• 2-1 / 2 cups rice - cooked\n•  3 tomatoes\n\n⌛ 15\n\n🍛 South Indian Recipes\n\n📝\n\n▪︎ To make tomato puliogere, first cut the tomatoes.\n▪︎ Now put in a mixer grinder and puree it.\n▪︎ Now heat oil in a pan.\n▪︎ After the oil is hot, add chana dal, urad dal, cashew and let it cook for 10 to 20 seconds.\n▪︎ After 10 to 20 seconds, add cumin seeds, mustard seeds, green chillies, dry red chillies and curry leaves.\n▪︎ After 30 seconds, add tomato puree to it and mix.\n▪︎ Add BC Belle Bhat powder, salt and mix it.\n▪︎ Allow to cook for 7 to 8 minutes and then turn off the gas.\n▪︎ Take it out in a bowl, add cooked rice and mix it.\n▪︎ Serve hot.\n▪︎ Serve tomato puliogre with tomato cucumber raita and papad for dinner.\n\n🌐 https://www.archanaskitchen.com/spicy-tomato-rice-recipe-in-hindi\n\n🍔\n\n• tomato\n• salt\n• chickpea lentils\n• green chilli\n• rice\n• mustard\n• bc belle bhat powder\n• dry red chilli\n• cashew peanuts\n• oilasafoetida\n• cumin seeds\n• white urad dal\n\n📷 https://www.archanaskitchen.com/images/archanaskitchen/1-Author/b.yojana-gmail.com/Spicy_Thakkali_Rice_Tomato_Pulihora-1_edited.jpg\n\n🥗 12\n\n\n\nRecipe #3\n---------\n📗 Ragi Semiya Upma Recipe - Ragi Millet Vermicelli Breakfast\n\n🥕\n\n• 1 Onion - sliced\n• 1 teaspoon White Urad Dal (Split)\n• 2 Green Chillies\n• Salt - to taste\n• 1 teaspoon Lemon juice\n• 1 teaspoon Ghee\n• 1 teaspoon Mustard seeds\n• 1/3 cup Green peas (Matar)\n• 1/4 teaspoon Asafoetida (hing)\n• 1/2 cup Carrots (Gajjar) - chopped\n• 1 sprig Curry leaves\n• 1-1/2 cups Rice Vermicelli Noodles (Thin)\n\n⌛ 50\n\n🍛 South Indian Recipes\n\n📝\n\n▪︎ To begin making the Ragi Vermicelli Recipe, first steam the ragi vermicelli in a rice cooker or a steamer for about 5-6 minutes or till it is cooked but firm.Keep aside this aside till later use.\n▪︎ You can add a few drops of oil and mix it so that they don't stick to each other.Place a kadai on the heat, add the ghee or oil to it and when warm add hing and allow it to sizzle for 30 seconds.\n▪︎ Then follow it up with mustard seeds, urad dal and curry leaves, and allow them to crackle.Saute for 1 minute or so till the urad dal is slightly browned.Then, add onions and fry till translucent and soft.Next, add the green chillies along with par boiled carrots and peas.\n▪︎ Sprinkle some salt and cook for 2-3 minutes or until the vegetables are semi cooked.Then, add the steamed ragi vermicelli toss it together so the vegetables are all well combined.Switch off the heat, take the vermicelli out into a serving dish and to with lemon juice.\n▪︎ Mix well and serve along with Coconut Chutney and a hot cup of coffee or tea for a wholesome breakfast.\n\n🌐 https://www.archanaskitchen.com/ragi-vermicelli-semiya-recipe-healthy-finger-millet-semiya-breakfast\n\n🍔\n\n• salt\n• rice vermicelli noodles (thin)\n• asafoetida (hing)\n• mustard seeds\n• ghee\n• green peas (matar)\n• carrot\n• curry leaves\n• white urad dal (split)\n• onion\n• lemon\n• green chillies\n\n📷 https://www.archanaskitchen.com/images/archanaskitchen/1-Author/Monika_Manchanda/Ragi_vermicilli.jpg\n\n🥗 12\n\n\n\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1681329959676
        }
      },
      "id": "d4469f8e"
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_stringified[1000])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "📗 Mushroom & Goat Cheese Omelette with Spinach Recipe\n\n🥕\n\n• Salt - to taste\n• 4 Spinach Leaves (Palak) - torn\n• 1/4 cup Milk\n• 100 grams Button mushrooms - quatered\n• 1 tablespoon Butter\n• 50 grams Goat Cheese\n• Sunflower Oil\n• 2 Whole Eggs\n• 1 teaspoon Black pepper powder\n• 1 teaspoon Dried oregano\n\n⌛ 30\n\n🍛 Continental\n\n📝\n\n▪︎ To begin making the Mushroom & Goat Cheese Omeltte with Spinach Recipe, break the eggs into a bowl, add milk and sprinkle some salt and whisk till it combines well.Heat a flat skillet with oil, add mushroom and saute until all the water has been evaporated.\n▪︎ Sprinkle with little salt.Once the mushroom is cooked, add dried oregano and pepper powder and mix well.\n▪︎ Toss well and transfer it to a bowl.Heat a flat nonstick skillet to make the omelette, add a tablespoon of butter.\n▪︎ Keep the heat to medium and slowly add the whisked eggs.Allow the egg to cook for 5 minutes.\n▪︎ Add sautéed mushroom, torn spinach leaves and crumbled goat cheese to one side and fold the omelette and serve warm.Serve the Mushroom & Goat Cheese Omelette with Spinach Recipe along with Zucchini Pancake Recipe With Tomato Salsa and Quick Strawberry Yogurt Smoothie Recipe.\n\n🌐 https://www.archanaskitchen.com/mushroom-goat-cheese-omeltte-with-spinach-recipe\n\n🍔\n\n• salt\n• button mushrooms\n• sunflower oil\n• milk\n• goat cheese\n• black pepper powder\n• eggs\n• spinach leaves (palak)\n• butter\n• dried oregano\n\n📷 https://www.archanaskitchen.com/images/archanaskitchen/1-Author/sibyl-archanaskitchen.com/Mushroom__Goat_Cheese_Omeltte_with_Spinach_Recipe.jpg\n\n🥗 10\n\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1681329960855
        }
      },
      "id": "b8e29066"
    },
    {
      "cell_type": "code",
      "source": [
        "recipes_lengths = []\n",
        "for recipe_text in dataset_stringified:\n",
        "    recipes_lengths.append(len(recipe_text))\n",
        "\n",
        "plt.hist(recipes_lengths, bins=50)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1681329961781
        }
      },
      "id": "09684e9e"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(recipes_lengths, range=(0, 6000), bins=50)\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1681329962776
        }
      },
      "id": "3ef0c3b3"
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_RECIPE_LENGTH = 5500"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1681329963688
        }
      },
      "id": "24cc1075"
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_recipes_by_length(recipe_test):\n",
        "    return len(recipe_test) <= MAX_RECIPE_LENGTH \n",
        "\n",
        "dataset_filtered = [recipe_text for recipe_text in dataset_stringified if filter_recipes_by_length(recipe_text)]\n",
        "\n",
        "print('Dataset size BEFORE filtering: ', len(dataset_stringified))\n",
        "print('Dataset size AFTER filtering: ', len(dataset_filtered))\n",
        "print('Number of eliminated recipes: ', len(dataset_stringified) - len(dataset_filtered))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Dataset size BEFORE filtering:  5938\nDataset size AFTER filtering:  5934\nNumber of eliminated recipes:  4\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1681329964523
        }
      },
      "id": "b9ec025c"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TOTAL_RECIPES_NUM = len(dataset_filtered)\n",
        "\n",
        "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
        "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MAX_RECIPE_LENGTH:  5500\nTOTAL_RECIPES_NUM:  5934\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1681329965487
        }
      },
      "id": "d4542882"
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_SIGN = '␣'\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    char_level=True,\n",
        "    filters='',\n",
        "    lower=False,\n",
        "    split=''\n",
        ")\n",
        "\n",
        "# Stop word is not a part of recipes, but tokenizer must know about it as well.\n",
        "tokenizer.fit_on_texts([STOP_SIGN])\n",
        "\n",
        "tokenizer.fit_on_texts(dataset_filtered)\n",
        "\n",
        "tokenizer.get_config()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "{'num_words': None,\n 'filters': '',\n 'lower': False,\n 'split': '',\n 'char_level': True,\n 'oov_token': None,\n 'document_count': 5935,\n 'word_counts': '{\"\\\\u2423\": 1, \"\\\\ud83d\\\\udcd7\": 5934, \" \": 1838116, \"M\": 23779, \"a\": 873324, \"s\": 494789, \"l\": 431453, \"K\": 13848, \"r\": 552474, \"e\": 1065807, \"R\": 38916, \"c\": 349837, \"i\": 624962, \"p\": 290139, \"\\\\n\": 309342, \"\\\\ud83e\\\\udd55\": 5934, \"\\\\u2022\": 142379, \"1\": 64011, \"t\": 684925, \"b\": 104342, \"o\": 640914, \"n\": 579266, \"d\": 389326, \"C\": 46774, \"h\": 394279, \"w\": 168510, \"3\": 10383, \"G\": 19437, \"m\": 218201, \"f\": 123182, \"u\": 255361, \"(\": 43399, \")\": 43230, \"2\": 32408, \"J\": 4252, \"P\": 30388, \"D\": 15959, \"T\": 27293, \"H\": 9446, \"S\": 49108, \"-\": 83545, \"A\": 30141, \"y\": 93244, \"g\": 184925, \"6\": 4003, \"B\": 21417, \"/\": 80366, \"v\": 65025, \"k\": 129152, \"O\": 17284, \"q\": 4385, \"\\\\u231b\": 5934, \"4\": 13093, \"5\": 10450, \"\\\\ud83c\\\\udf5b\": 5934, \"I\": 11324, \"\\\\ud83d\\\\udcdd\": 5934, \"\\\\u25aa\": 48283, \"\\\\ufe0e\": 48283, \",\": 59261, \".\": 115702, \"z\": 10583, \"x\": 20461, \"\\\\ud83c\\\\udf10\": 5934, \":\": 12139, \"\\\\ud83c\\\\udf54\": 5934, \"j\": 24655, \"\\\\ud83d\\\\udcf7\": 5934, \"_\": 34109, \"0\": 18195, \"\\\\ud83e\\\\udd57\": 5934, \"N\": 8735, \"7\": 1885, \"8\": 3012, \"U\": 2262, \"V\": 5364, \"W\": 12039, \"L\": 8936, \"Y\": 3514, \"\\'\": 839, \"F\": 11154, \";\": 896, \"|\": 176, \"&\": 2381, \"E\": 5471, \"\\\\u00e9\": 830, \"9\": 1284, \"[\": 14, \"]\": 16, \"\\\\u2013\": 50, \"!\": 110, \"+\": 112, \"\\\\ufeff\": 96, \"\\\\\"\": 146, \"*\": 160, \"Z\": 385, \"Q\": 470, \"\\\\u2019\": 367, \"\\\\u00b0\": 49, \"\\\\u201c\": 34, \"\\\\u201d\": 47, \"\\\\u00bc\": 20, \"=\": 6, \"\\\\u2018\": 69, \"%\": 38, \"X\": 39, \"\\\\u00bd\": 53, \"\\\\u00f1\": 18, \"\\\\u00e1\": 16, \"\\\\u00ec\": 12, \"~\": 2, \"<\": 1, \"\\\\u2153\": 2, \"\\\\u00be\": 5, \"\\\\u00e8\": 17, \"\\\\u2033\": 4, \"`\": 4, \"\\\\u00e7\": 4, \"\\\\u00f6\": 2, \"\\\\u2014\": 1, \"\\\\u200b\": 1, \"\\\\u02da\": 3, \"\\\\u2009\": 1, \"\\\\u00d7\": 1, \"\\\\u092c\": 1, \"\\\\u095c\": 1, \"\\\\u0947\": 1, \"\\\\u091a\": 3, \"\\\\u092e\": 1, \"\\\\u094d\": 1, \"\\\\u0939\": 1, \"\\\\u0940\": 1, \"\\\\u0902\": 1, \"\\\\u0917\": 1, \"\\\\u00f3\": 1, \"\\\\u039c\": 3, \"\\\\u03b1\": 6, \"\\\\u03c5\": 3, \"\\\\u03c1\": 3, \"\\\\u03bf\": 3, \"\\\\u03bc\": 3, \"\\\\u03ac\": 3, \"\\\\u03c4\": 3, \"\\\\u03b9\": 3, \"\\\\u03ba\": 3, \"\\\\uff5c\": 2, \"\\\\u2154\": 1, \"\\\\u00e2\": 2, \"\\\\u00c6\": 6, \"@\": 1, \"{\": 1, \"}\": 1, \"\\\\u2103\": 1}',\n 'word_docs': '{\"\\\\u2423\": 1, \"H\": 4414, \" \": 5934, \"h\": 5934, \"I\": 4757, \"v\": 5930, \"R\": 5930, \"b\": 5934, \"C\": 5853, \"r\": 5934, \":\": 5934, \"4\": 5096, \"o\": 5934, \"P\": 5576, \"l\": 5934, \"a\": 5934, \"\\\\ud83e\\\\udd55\": 5934, \"\\\\ud83d\\\\udcd7\": 5934, \"\\\\ud83d\\\\udcf7\": 5934, \"\\\\ufe0e\": 5934, \"_\": 5880, \"/\": 5934, \"\\\\u25aa\": 5934, \")\": 5586, \"\\\\ud83c\\\\udf5b\": 5934, \"m\": 5934, \"g\": 5934, \"t\": 5934, \"M\": 5309, \"d\": 5934, \"D\": 4964, \"5\": 4821, \"2\": 5852, \"\\\\ud83c\\\\udf54\": 5934, \"\\\\ud83d\\\\udcdd\": 5934, \"j\": 5927, \"0\": 5356, \"s\": 5934, \"K\": 4081, \"\\\\n\": 5934, \"\\\\u2022\": 5934, \".\": 5934, \"T\": 5916, \"6\": 2816, \"u\": 5934, \"(\": 5593, \"3\": 4700, \"z\": 2927, \"q\": 2507, \"n\": 5934, \"i\": 5934, \"w\": 5934, \"f\": 5930, \"S\": 5925, \"-\": 5934, \"A\": 5871, \"G\": 5160, \"e\": 5934, \"1\": 5933, \"c\": 5934, \"B\": 4950, \",\": 5912, \"O\": 5145, \"y\": 5931, \"\\\\u231b\": 5934, \"x\": 5373, \"\\\\ud83c\\\\udf10\": 5934, \"\\\\ud83e\\\\udd57\": 5934, \"p\": 5934, \"J\": 2647, \"k\": 5934, \"7\": 1534, \"N\": 3756, \"8\": 2188, \"V\": 2416, \"\\'\": 597, \"L\": 3933, \"U\": 1175, \"Y\": 2347, \"W\": 4267, \"|\": 108, \";\": 599, \"F\": 4253, \"E\": 2756, \"&\": 1198, \"\\\\u00e9\": 556, \"9\": 1147, \"]\": 9, \"!\": 89, \"\\\\u2013\": 40, \"[\": 7, \"+\": 97, \"\\\\ufeff\": 96, \"*\": 87, \"\\\\\"\": 72, \"Z\": 173, \"Q\": 159, \"\\\\u2019\": 306, \"\\\\u00b0\": 36, \"\\\\u201c\": 34, \"\\\\u201d\": 38, \"\\\\u00bc\": 16, \"=\": 5, \"\\\\u2018\": 59, \"%\": 32, \"X\": 24, \"\\\\u00bd\": 50, \"\\\\u00f1\": 15, \"\\\\u00ec\": 3, \"\\\\u00e1\": 5, \"~\": 1, \"<\": 1, \"\\\\u2153\": 1, \"\\\\u00be\": 4, \"\\\\u00e8\": 9, \"\\\\u2033\": 3, \"`\": 4, \"\\\\u00e7\": 2, \"\\\\u00f6\": 1, \"\\\\u2014\": 1, \"\\\\u200b\": 1, \"\\\\u02da\": 2, \"\\\\u2009\": 1, \"\\\\u00d7\": 1, \"\\\\u0902\": 1, \"\\\\u0947\": 1, \"\\\\u0940\": 1, \"\\\\u0939\": 1, \"\\\\u0917\": 1, \"\\\\u092c\": 1, \"\\\\u095c\": 1, \"\\\\u094d\": 1, \"\\\\u091a\": 1, \"\\\\u092e\": 1, \"\\\\u00f3\": 1, \"\\\\u03ba\": 1, \"\\\\u03b1\": 1, \"\\\\u03c1\": 1, \"\\\\u03bf\": 1, \"\\\\u03ac\": 1, \"\\\\u03b9\": 1, \"\\\\u03c4\": 1, \"\\\\u03bc\": 1, \"\\\\u03c5\": 1, \"\\\\u039c\": 1, \"\\\\uff5c\": 1, \"\\\\u2154\": 1, \"\\\\u00e2\": 1, \"\\\\u00c6\": 1, \"@\": 1, \"{\": 1, \"}\": 1, \"\\\\u2103\": 1}',\n 'index_docs': '{\"1\": 5934, \"133\": 1, \"60\": 4414, \"11\": 5934, \"55\": 4757, \"28\": 5930, \"37\": 5930, \"24\": 5934, \"34\": 5853, \"8\": 5934, \"53\": 5934, \"52\": 5096, \"5\": 5934, \"40\": 5576, \"10\": 5934, \"3\": 5934, \"64\": 5934, \"63\": 5934, \"70\": 5934, \"33\": 5934, \"38\": 5880, \"27\": 5934, \"32\": 5934, \"36\": 5586, \"66\": 5934, \"17\": 5934, \"18\": 5934, \"4\": 5934, \"44\": 5309, \"12\": 5934, \"50\": 4964, \"58\": 4821, \"39\": 5852, \"69\": 5934, \"67\": 5934, \"43\": 5927, \"48\": 5356, \"9\": 5934, \"51\": 4081, \"14\": 5934, \"20\": 5934, \"23\": 5934, \"42\": 5916, \"76\": 2816, \"16\": 5934, \"35\": 5593, \"59\": 4700, \"57\": 2927, \"74\": 2507, \"7\": 5934, \"6\": 5934, \"19\": 5934, \"22\": 5930, \"31\": 5925, \"26\": 5934, \"41\": 5871, \"47\": 5160, \"2\": 5934, \"29\": 5933, \"13\": 5934, \"45\": 4950, \"30\": 5912, \"49\": 5145, \"25\": 5931, \"65\": 5934, \"46\": 5373, \"68\": 5934, \"71\": 5934, \"15\": 5934, \"75\": 2647, \"21\": 5934, \"81\": 1534, \"62\": 3756, \"78\": 2188, \"73\": 2416, \"84\": 597, \"61\": 3933, \"80\": 1175, \"77\": 2347, \"54\": 4267, \"89\": 108, \"83\": 599, \"56\": 4253, \"72\": 2756, \"79\": 1198, \"85\": 556, \"82\": 1147, \"106\": 9, \"93\": 89, \"97\": 40, \"108\": 7, \"92\": 97, \"94\": 96, \"90\": 87, \"91\": 72, \"87\": 173, \"86\": 159, \"88\": 306, \"98\": 36, \"102\": 34, \"99\": 38, \"103\": 16, \"110\": 5, \"95\": 59, \"101\": 32, \"100\": 24, \"96\": 50, \"104\": 15, \"109\": 3, \"107\": 5, \"128\": 1, \"134\": 1, \"129\": 1, \"113\": 4, \"105\": 9, \"114\": 3, \"115\": 4, \"116\": 2, \"130\": 1, \"135\": 1, \"136\": 1, \"117\": 2, \"137\": 1, \"138\": 1, \"146\": 1, \"141\": 1, \"145\": 1, \"144\": 1, \"147\": 1, \"139\": 1, \"140\": 1, \"143\": 1, \"118\": 1, \"142\": 1, \"148\": 1, \"127\": 1, \"111\": 1, \"121\": 1, \"122\": 1, \"124\": 1, \"126\": 1, \"125\": 1, \"123\": 1, \"120\": 1, \"119\": 1, \"131\": 1, \"149\": 1, \"132\": 1, \"112\": 1, \"150\": 1, \"151\": 1, \"152\": 1, \"153\": 1}',\n 'index_word': '{\"1\": \" \", \"2\": \"e\", \"3\": \"a\", \"4\": \"t\", \"5\": \"o\", \"6\": \"i\", \"7\": \"n\", \"8\": \"r\", \"9\": \"s\", \"10\": \"l\", \"11\": \"h\", \"12\": \"d\", \"13\": \"c\", \"14\": \"\\\\n\", \"15\": \"p\", \"16\": \"u\", \"17\": \"m\", \"18\": \"g\", \"19\": \"w\", \"20\": \"\\\\u2022\", \"21\": \"k\", \"22\": \"f\", \"23\": \".\", \"24\": \"b\", \"25\": \"y\", \"26\": \"-\", \"27\": \"/\", \"28\": \"v\", \"29\": \"1\", \"30\": \",\", \"31\": \"S\", \"32\": \"\\\\u25aa\", \"33\": \"\\\\ufe0e\", \"34\": \"C\", \"35\": \"(\", \"36\": \")\", \"37\": \"R\", \"38\": \"_\", \"39\": \"2\", \"40\": \"P\", \"41\": \"A\", \"42\": \"T\", \"43\": \"j\", \"44\": \"M\", \"45\": \"B\", \"46\": \"x\", \"47\": \"G\", \"48\": \"0\", \"49\": \"O\", \"50\": \"D\", \"51\": \"K\", \"52\": \"4\", \"53\": \":\", \"54\": \"W\", \"55\": \"I\", \"56\": \"F\", \"57\": \"z\", \"58\": \"5\", \"59\": \"3\", \"60\": \"H\", \"61\": \"L\", \"62\": \"N\", \"63\": \"\\\\ud83d\\\\udcd7\", \"64\": \"\\\\ud83e\\\\udd55\", \"65\": \"\\\\u231b\", \"66\": \"\\\\ud83c\\\\udf5b\", \"67\": \"\\\\ud83d\\\\udcdd\", \"68\": \"\\\\ud83c\\\\udf10\", \"69\": \"\\\\ud83c\\\\udf54\", \"70\": \"\\\\ud83d\\\\udcf7\", \"71\": \"\\\\ud83e\\\\udd57\", \"72\": \"E\", \"73\": \"V\", \"74\": \"q\", \"75\": \"J\", \"76\": \"6\", \"77\": \"Y\", \"78\": \"8\", \"79\": \"&\", \"80\": \"U\", \"81\": \"7\", \"82\": \"9\", \"83\": \";\", \"84\": \"\\'\", \"85\": \"\\\\u00e9\", \"86\": \"Q\", \"87\": \"Z\", \"88\": \"\\\\u2019\", \"89\": \"|\", \"90\": \"*\", \"91\": \"\\\\\"\", \"92\": \"+\", \"93\": \"!\", \"94\": \"\\\\ufeff\", \"95\": \"\\\\u2018\", \"96\": \"\\\\u00bd\", \"97\": \"\\\\u2013\", \"98\": \"\\\\u00b0\", \"99\": \"\\\\u201d\", \"100\": \"X\", \"101\": \"%\", \"102\": \"\\\\u201c\", \"103\": \"\\\\u00bc\", \"104\": \"\\\\u00f1\", \"105\": \"\\\\u00e8\", \"106\": \"]\", \"107\": \"\\\\u00e1\", \"108\": \"[\", \"109\": \"\\\\u00ec\", \"110\": \"=\", \"111\": \"\\\\u03b1\", \"112\": \"\\\\u00c6\", \"113\": \"\\\\u00be\", \"114\": \"\\\\u2033\", \"115\": \"`\", \"116\": \"\\\\u00e7\", \"117\": \"\\\\u02da\", \"118\": \"\\\\u091a\", \"119\": \"\\\\u039c\", \"120\": \"\\\\u03c5\", \"121\": \"\\\\u03c1\", \"122\": \"\\\\u03bf\", \"123\": \"\\\\u03bc\", \"124\": \"\\\\u03ac\", \"125\": \"\\\\u03c4\", \"126\": \"\\\\u03b9\", \"127\": \"\\\\u03ba\", \"128\": \"~\", \"129\": \"\\\\u2153\", \"130\": \"\\\\u00f6\", \"131\": \"\\\\uff5c\", \"132\": \"\\\\u00e2\", \"133\": \"\\\\u2423\", \"134\": \"<\", \"135\": \"\\\\u2014\", \"136\": \"\\\\u200b\", \"137\": \"\\\\u2009\", \"138\": \"\\\\u00d7\", \"139\": \"\\\\u092c\", \"140\": \"\\\\u095c\", \"141\": \"\\\\u0947\", \"142\": \"\\\\u092e\", \"143\": \"\\\\u094d\", \"144\": \"\\\\u0939\", \"145\": \"\\\\u0940\", \"146\": \"\\\\u0902\", \"147\": \"\\\\u0917\", \"148\": \"\\\\u00f3\", \"149\": \"\\\\u2154\", \"150\": \"@\", \"151\": \"{\", \"152\": \"}\", \"153\": \"\\\\u2103\"}',\n 'word_index': '{\" \": 1, \"e\": 2, \"a\": 3, \"t\": 4, \"o\": 5, \"i\": 6, \"n\": 7, \"r\": 8, \"s\": 9, \"l\": 10, \"h\": 11, \"d\": 12, \"c\": 13, \"\\\\n\": 14, \"p\": 15, \"u\": 16, \"m\": 17, \"g\": 18, \"w\": 19, \"\\\\u2022\": 20, \"k\": 21, \"f\": 22, \".\": 23, \"b\": 24, \"y\": 25, \"-\": 26, \"/\": 27, \"v\": 28, \"1\": 29, \",\": 30, \"S\": 31, \"\\\\u25aa\": 32, \"\\\\ufe0e\": 33, \"C\": 34, \"(\": 35, \")\": 36, \"R\": 37, \"_\": 38, \"2\": 39, \"P\": 40, \"A\": 41, \"T\": 42, \"j\": 43, \"M\": 44, \"B\": 45, \"x\": 46, \"G\": 47, \"0\": 48, \"O\": 49, \"D\": 50, \"K\": 51, \"4\": 52, \":\": 53, \"W\": 54, \"I\": 55, \"F\": 56, \"z\": 57, \"5\": 58, \"3\": 59, \"H\": 60, \"L\": 61, \"N\": 62, \"\\\\ud83d\\\\udcd7\": 63, \"\\\\ud83e\\\\udd55\": 64, \"\\\\u231b\": 65, \"\\\\ud83c\\\\udf5b\": 66, \"\\\\ud83d\\\\udcdd\": 67, \"\\\\ud83c\\\\udf10\": 68, \"\\\\ud83c\\\\udf54\": 69, \"\\\\ud83d\\\\udcf7\": 70, \"\\\\ud83e\\\\udd57\": 71, \"E\": 72, \"V\": 73, \"q\": 74, \"J\": 75, \"6\": 76, \"Y\": 77, \"8\": 78, \"&\": 79, \"U\": 80, \"7\": 81, \"9\": 82, \";\": 83, \"\\'\": 84, \"\\\\u00e9\": 85, \"Q\": 86, \"Z\": 87, \"\\\\u2019\": 88, \"|\": 89, \"*\": 90, \"\\\\\"\": 91, \"+\": 92, \"!\": 93, \"\\\\ufeff\": 94, \"\\\\u2018\": 95, \"\\\\u00bd\": 96, \"\\\\u2013\": 97, \"\\\\u00b0\": 98, \"\\\\u201d\": 99, \"X\": 100, \"%\": 101, \"\\\\u201c\": 102, \"\\\\u00bc\": 103, \"\\\\u00f1\": 104, \"\\\\u00e8\": 105, \"]\": 106, \"\\\\u00e1\": 107, \"[\": 108, \"\\\\u00ec\": 109, \"=\": 110, \"\\\\u03b1\": 111, \"\\\\u00c6\": 112, \"\\\\u00be\": 113, \"\\\\u2033\": 114, \"`\": 115, \"\\\\u00e7\": 116, \"\\\\u02da\": 117, \"\\\\u091a\": 118, \"\\\\u039c\": 119, \"\\\\u03c5\": 120, \"\\\\u03c1\": 121, \"\\\\u03bf\": 122, \"\\\\u03bc\": 123, \"\\\\u03ac\": 124, \"\\\\u03c4\": 125, \"\\\\u03b9\": 126, \"\\\\u03ba\": 127, \"~\": 128, \"\\\\u2153\": 129, \"\\\\u00f6\": 130, \"\\\\uff5c\": 131, \"\\\\u00e2\": 132, \"\\\\u2423\": 133, \"<\": 134, \"\\\\u2014\": 135, \"\\\\u200b\": 136, \"\\\\u2009\": 137, \"\\\\u00d7\": 138, \"\\\\u092c\": 139, \"\\\\u095c\": 140, \"\\\\u0947\": 141, \"\\\\u092e\": 142, \"\\\\u094d\": 143, \"\\\\u0939\": 144, \"\\\\u0940\": 145, \"\\\\u0902\": 146, \"\\\\u0917\": 147, \"\\\\u00f3\": 148, \"\\\\u2154\": 149, \"@\": 150, \"{\": 151, \"}\": 152, \"\\\\u2103\": 153}'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1681329967949
        }
      },
      "id": "ed74676e"
    },
    {
      "cell_type": "code",
      "source": [
        "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1\n",
        "\n",
        "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "VOCABULARY_SIZE:  154\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1681329968891
        }
      },
      "id": "dfd425d4"
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,154):\n",
        "  print(tokenizer.index_word[i],end=\" \")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "  e a t o i n r s l h d c \n p u m g w • k f . b y - / v 1 , S ▪ ︎ C ( ) R _ 2 P A T j M B x G 0 O D K 4 : W I F z 5 3 H L N 📗 🥕 ⌛ 🍛 📝 🌐 🍔 📷 🥗 E V q J 6 Y 8 & U 7 9 ; ' é Q Z ’ | * \" + ! ﻿ ‘ ½ – ° ” X % “ ¼ ñ è ] á [ ì = α Æ ¾ ″ ` ç ˚ च Μ υ ρ ο μ ά τ ι κ ~ ⅓ ö ｜ â ␣ < — ​   × ब ड़ े म ् ह ी ं ग ó ⅔ @ { } ℃ "
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1681329969416
        }
      },
      "id": "bc02a325"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['r']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "8"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1681329969977
        }
      },
      "id": "db737518"
    },
    {
      "cell_type": "code",
      "source": [
        "array_vocabulary = tokenizer.sequences_to_texts([[word_index] for word_index in range(VOCABULARY_SIZE)])\n",
        "print([char for char in array_vocabulary])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['', ' ', 'e', 'a', 't', 'o', 'i', 'n', 'r', 's', 'l', 'h', 'd', 'c', '\\n', 'p', 'u', 'm', 'g', 'w', '•', 'k', 'f', '.', 'b', 'y', '-', '/', 'v', '1', ',', 'S', '▪', '︎', 'C', '(', ')', 'R', '_', '2', 'P', 'A', 'T', 'j', 'M', 'B', 'x', 'G', '0', 'O', 'D', 'K', '4', ':', 'W', 'I', 'F', 'z', '5', '3', 'H', 'L', 'N', '📗', '🥕', '⌛', '🍛', '📝', '🌐', '🍔', '📷', '🥗', 'E', 'V', 'q', 'J', '6', 'Y', '8', '&', 'U', '7', '9', ';', \"'\", 'é', 'Q', 'Z', '’', '|', '*', '\"', '+', '!', '\\ufeff', '‘', '½', '–', '°', '”', 'X', '%', '“', '¼', 'ñ', 'è', ']', 'á', '[', 'ì', '=', 'α', 'Æ', '¾', '″', '`', 'ç', '˚', 'च', 'Μ', 'υ', 'ρ', 'ο', 'μ', 'ά', 'τ', 'ι', 'κ', '~', '⅓', 'ö', '｜', 'â', '␣', '<', '—', '\\u200b', '\\u2009', '×', 'ब', 'ड़', 'े', 'म', '्', 'ह', 'ी', 'ं', 'ग', 'ó', '⅔', '@', '{', '}', '℃']\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1681329970534
        }
      },
      "id": "28554411"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(['📗 yes'])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "[[63, 1, 25, 2, 9]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1681329971113
        }
      },
      "id": "efa3ef6b"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vectorized = tokenizer.texts_to_sequences(dataset_filtered)\n",
        "\n",
        "print('Vectorized dataset size', len(dataset_vectorized))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Vectorized dataset size 5934\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1681329972090
        }
      },
      "id": "2be8800c"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vectorized[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "[63,\n 1,\n 44,\n 3,\n 9,\n 3,\n 10,\n 3,\n 1,\n 51,\n 3,\n 8,\n 2,\n 10,\n 3,\n 1,\n 37,\n 2,\n 13,\n 6,\n 15,\n 2,\n 14,\n 14,\n 64,\n 14,\n 14,\n 20,\n 1,\n 29,\n 1,\n 4,\n 3,\n 24,\n 10,\n 2,\n 9,\n 15,\n 5,\n 5,\n 7,\n 1,\n 37,\n 2,\n 12,\n 1,\n 34,\n 11,\n 6,\n 10,\n 10,\n 6,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 14,\n 20,\n 1,\n 59,\n 1,\n 4,\n 3,\n 24,\n 10,\n 2,\n 9,\n 15,\n 5,\n 5,\n 7,\n 1,\n 47,\n 8,\n 3,\n 17,\n 1,\n 22,\n 10,\n 5,\n 16,\n 8,\n 1,\n 35,\n 24,\n 2,\n 9,\n 3,\n 7,\n 36,\n 14,\n 20,\n 1,\n 39,\n 1,\n 4,\n 2,\n 3,\n 9,\n 15,\n 5,\n 5,\n 7,\n 9,\n 1,\n 34,\n 16,\n 17,\n 6,\n 7,\n 1,\n 9,\n 2,\n 2,\n 12,\n 9,\n 1,\n 35,\n 75,\n 2,\n 2,\n 8,\n 3,\n 36,\n 14,\n 20,\n 1,\n 29,\n 1,\n 4,\n 3,\n 24,\n 10,\n 2,\n 9,\n 15,\n 5,\n 5,\n 7,\n 1,\n 34,\n 5,\n 8,\n 6,\n 3,\n 7,\n 12,\n 2,\n 8,\n 1,\n 40,\n 5,\n 19,\n 12,\n 2,\n 8,\n 1,\n 35,\n 50,\n 11,\n 3,\n 7,\n 6,\n 3,\n 36,\n 14,\n 20,\n 1,\n 39,\n 1,\n 4,\n 2,\n 3,\n 9,\n 15,\n 5,\n 5,\n 7,\n 9,\n 1,\n 42,\n 16,\n 8,\n 17,\n 2,\n 8,\n 6,\n 13,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 1,\n 35,\n 60,\n 3,\n 10,\n 12,\n 6,\n 36,\n 14,\n 20,\n 1,\n 31,\n 3,\n 10,\n 4,\n 1,\n 26,\n 1,\n 4,\n 5,\n 1,\n 4,\n 3,\n 9,\n 4,\n 2,\n 14,\n 20,\n 1,\n 29,\n 1,\n 4,\n 3,\n 24,\n 10,\n 2,\n 9,\n 15,\n 5,\n 5,\n 7,\n 1,\n 41,\n 17,\n 13,\n 11,\n 16,\n 8,\n 1,\n 35,\n 50,\n 8,\n 25,\n 1,\n 44,\n 3,\n 7,\n 18,\n 5,\n 1,\n 40,\n 5,\n 19,\n 12,\n 2,\n 8,\n 36,\n 14,\n 20,\n 1,\n 76,\n 1,\n 51,\n 3,\n 8,\n 2,\n 10,\n 3,\n 1,\n 35,\n 45,\n 6,\n 4,\n 4,\n 2,\n 8,\n 1,\n 47,\n 5,\n 16,\n 8,\n 12,\n 27,\n 1,\n 40,\n 3,\n 28,\n 3,\n 21,\n 21,\n 3,\n 6,\n 36,\n 1,\n 26,\n 1,\n 12,\n 2,\n 9,\n 2,\n 2,\n 12,\n 2,\n 12,\n 14,\n 20,\n 1,\n 31,\n 16,\n 7,\n 22,\n 10,\n 5,\n 19,\n 2,\n 8,\n 1,\n 49,\n 6,\n 10,\n 1,\n 26,\n 1,\n 3,\n 9,\n 1,\n 8,\n 2,\n 74,\n 16,\n 6,\n 8,\n 2,\n 12,\n 14,\n 20,\n 1,\n 29,\n 1,\n 49,\n 7,\n 6,\n 5,\n 7,\n 1,\n 26,\n 1,\n 4,\n 11,\n 6,\n 7,\n 10,\n 25,\n 1,\n 9,\n 10,\n 6,\n 13,\n 2,\n 12,\n 14,\n 14,\n 65,\n 1,\n 52,\n 58,\n 14,\n 14,\n 66,\n 1,\n 55,\n 7,\n 12,\n 6,\n 3,\n 7,\n 14,\n 14,\n 67,\n 14,\n 14,\n 32,\n 33,\n 1,\n 42,\n 5,\n 1,\n 24,\n 2,\n 18,\n 6,\n 7,\n 1,\n 17,\n 3,\n 21,\n 6,\n 7,\n 18,\n 1,\n 4,\n 11,\n 2,\n 1,\n 44,\n 3,\n 9,\n 3,\n 10,\n 3,\n 1,\n 51,\n 3,\n 8,\n 2,\n 10,\n 3,\n 1,\n 37,\n 2,\n 13,\n 6,\n 15,\n 2,\n 30,\n 12,\n 2,\n 26,\n 9,\n 2,\n 2,\n 12,\n 1,\n 4,\n 11,\n 2,\n 1,\n 21,\n 3,\n 8,\n 2,\n 10,\n 3,\n 1,\n 3,\n 7,\n 12,\n 1,\n 9,\n 10,\n 6,\n 13,\n 2,\n 23,\n 14,\n 32,\n 33,\n 1,\n 50,\n 5,\n 1,\n 7,\n 5,\n 4,\n 1,\n 8,\n 2,\n 17,\n 5,\n 28,\n 2,\n 1,\n 4,\n 11,\n 2,\n 1,\n 9,\n 21,\n 6,\n 7,\n 1,\n 3,\n 9,\n 1,\n 4,\n 11,\n 2,\n 1,\n 9,\n 21,\n 6,\n 7,\n 1,\n 11,\n 3,\n 9,\n 1,\n 3,\n 10,\n 10,\n 1,\n 4,\n 11,\n 2,\n 1,\n 7,\n 16,\n 4,\n 8,\n 6,\n 2,\n 7,\n 4,\n 9,\n 23,\n 14,\n 32,\n 33,\n 1,\n 41,\n 12,\n 12,\n 1,\n 4,\n 11,\n 2,\n 1,\n 21,\n 3,\n 8,\n 2,\n 10,\n 3,\n 1,\n 4,\n 5,\n 1,\n 4,\n 11,\n 2,\n 1,\n 15,\n 8,\n 2,\n 9,\n 9,\n 16,\n 8,\n 2,\n 1,\n 13,\n 5,\n 5,\n 21,\n 2,\n 8,\n 1,\n 19,\n 6,\n 4,\n 11,\n 1,\n 59,\n 1,\n 4,\n 3,\n 24,\n 10,\n 2,\n 9,\n 15,\n 5,\n 5,\n 7,\n 1,\n 5,\n 22,\n 1,\n 19,\n 3,\n 4,\n 2,\n 8,\n 30,\n 1,\n 9,\n 3,\n 10,\n 4,\n 1,\n 3,\n 7,\n 12,\n 1,\n 4,\n 16,\n 8,\n 17,\n 2,\n 8,\n 6,\n 13,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 1,\n 3,\n 7,\n 12,\n 1,\n 15,\n 8,\n 2,\n 9,\n 9,\n 16,\n 8,\n 2,\n 1,\n 13,\n 5,\n 5,\n 21,\n 1,\n 22,\n 5,\n 8,\n 1,\n 4,\n 11,\n 8,\n 2,\n 2,\n 1,\n 19,\n 11,\n 6,\n 9,\n 4,\n 10,\n 2,\n 9,\n 23,\n 14,\n 32,\n 33,\n 1,\n 37,\n 2,\n 10,\n 2,\n 3,\n 9,\n 2,\n 1,\n 4,\n 11,\n 2,\n 1,\n 15,\n 8,\n 2,\n 9,\n 9,\n 16,\n 8,\n 2,\n 1,\n 6,\n 17,\n 17,\n 2,\n 12,\n 6,\n 3,\n 4,\n 2,\n 10,\n 25,\n 1,\n 3,\n 7,\n 12,\n 1,\n 5,\n 15,\n 2,\n 7,\n 1,\n 4,\n 11,\n 2,\n 1,\n 10,\n 6,\n 12,\n 9,\n 23,\n 14,\n 32,\n 33,\n 1,\n 51,\n 2,\n 2,\n 15,\n 1,\n 3,\n 9,\n 6,\n 12,\n 2,\n 23,\n 60,\n 2,\n 3,\n 4,\n 1,\n 5,\n 6,\n 10,\n 1,\n 6,\n 7,\n 1,\n 3,\n 1,\n 11,\n 2,\n 3,\n 28,\n 25,\n 1,\n 24,\n 5,\n 4,\n 4,\n 5,\n 17,\n 2,\n 12,\n 1,\n 15,\n 3,\n 7,\n 1,\n 5,\n 8,\n 1,\n 3,\n 1,\n 21,\n 3,\n 12,\n 11,\n 3,\n 6,\n 23,\n 14,\n 32,\n 33,\n 1,\n 41,\n 12,\n 12,\n 1,\n 13,\n 16,\n 17,\n 6,\n 7,\n 1,\n 9,\n 2,\n 2,\n 12,\n 9,\n 1,\n 3,\n 7,\n 12,\n 1,\n 10,\n 2,\n 4,\n 1,\n 6,\n 4,\n 1,\n 9,\n 6,\n 57,\n 57,\n 10,\n 2,\n 23,\n 49,\n 7,\n 13,\n 2,\n 1,\n 4,\n 11,\n 2,\n 1,\n 13,\n 16,\n 17,\n 6,\n 7,\n 1,\n 9,\n 2,\n 2,\n 12,\n 9,\n 1,\n 11,\n 3,\n 28,\n 2,\n 1,\n 9,\n 6,\n 57,\n 57,\n 10,\n 2,\n 12,\n 30,\n 1,\n 3,\n 12,\n 12,\n 1,\n 5,\n 7,\n 6,\n 5,\n 7,\n 9,\n 1,\n 3,\n 7,\n 12,\n 1,\n 9,\n 3,\n 16,\n 4,\n 2,\n 1,\n 4,\n 11,\n 2,\n 17,\n 1,\n 4,\n 6,\n 10,\n 10,\n 1,\n 6,\n 4,\n 1,\n 4,\n 16,\n 8,\n 7,\n 9,\n 1,\n 18,\n 5,\n 10,\n 12,\n 2,\n 7,\n 1,\n 24,\n 8,\n 5,\n 19,\n 7,\n 1,\n 6,\n 7,\n 1,\n 13,\n 5,\n 10,\n 5,\n 8,\n 23,\n 41,\n 12,\n 12,\n 1,\n 4,\n 11,\n 2,\n 1,\n 21,\n 3,\n 8,\n 2,\n 10,\n 3,\n 30,\n 1,\n 8,\n 2,\n 12,\n 1,\n 13,\n 11,\n 6,\n 10,\n 10,\n 6,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 30,\n 1,\n 3,\n 17,\n 13,\n 11,\n 16,\n 8,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 30,\n 1,\n 13,\n 5,\n 8,\n 6,\n 3,\n 7,\n 12,\n 2,\n 8,\n 1,\n 15,\n 5,\n 19,\n 12,\n 2,\n 8,\n 1,\n 3,\n 7,\n 12,\n 1,\n 24,\n 2,\n 9,\n 3,\n 7,\n 23,\n 14,\n 32,\n 33,\n 1,\n 31,\n 4,\n 6,\n 8,\n 1,\n 4,\n 5,\n 1,\n 13,\n 5,\n 17,\n 24,\n 6,\n 7,\n ...]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1681329972766
        }
      },
      "id": "65de89c6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_vectorized[0][:10], '...')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[63, 1, 44, 3, 9, 3, 10, 3, 1, 51] ...\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1681329973740
        }
      },
      "id": "c2255902"
    },
    {
      "cell_type": "code",
      "source": [
        "def recipe_sequence_to_string(recipe_sequence):\n",
        "    recipe_stringified = tokenizer.sequences_to_texts([recipe_sequence])[0]\n",
        "    print(recipe_stringified)\n",
        "\n",
        "recipe_sequence_to_string(dataset_vectorized[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "📗   M a s a l a   K a r e l a   R e c i p e \n \n 🥕 \n \n •   1   t a b l e s p o o n   R e d   C h i l l i   p o w d e r \n •   3   t a b l e s p o o n   G r a m   f l o u r   ( b e s a n ) \n •   2   t e a s p o o n s   C u m i n   s e e d s   ( J e e r a ) \n •   1   t a b l e s p o o n   C o r i a n d e r   P o w d e r   ( D h a n i a ) \n •   2   t e a s p o o n s   T u r m e r i c   p o w d e r   ( H a l d i ) \n •   S a l t   -   t o   t a s t e \n •   1   t a b l e s p o o n   A m c h u r   ( D r y   M a n g o   P o w d e r ) \n •   6   K a r e l a   ( B i t t e r   G o u r d /   P a v a k k a i )   -   d e s e e d e d \n •   S u n f l o w e r   O i l   -   a s   r e q u i r e d \n •   1   O n i o n   -   t h i n l y   s l i c e d \n \n ⌛   4 5 \n \n 🍛   I n d i a n \n \n 📝 \n \n ▪ ︎   T o   b e g i n   m a k i n g   t h e   M a s a l a   K a r e l a   R e c i p e , d e - s e e d   t h e   k a r e l a   a n d   s l i c e . \n ▪ ︎   D o   n o t   r e m o v e   t h e   s k i n   a s   t h e   s k i n   h a s   a l l   t h e   n u t r i e n t s . \n ▪ ︎   A d d   t h e   k a r e l a   t o   t h e   p r e s s u r e   c o o k e r   w i t h   3   t a b l e s p o o n   o f   w a t e r ,   s a l t   a n d   t u r m e r i c   p o w d e r   a n d   p r e s s u r e   c o o k   f o r   t h r e e   w h i s t l e s . \n ▪ ︎   R e l e a s e   t h e   p r e s s u r e   i m m e d i a t e l y   a n d   o p e n   t h e   l i d s . \n ▪ ︎   K e e p   a s i d e . H e a t   o i l   i n   a   h e a v y   b o t t o m e d   p a n   o r   a   k a d h a i . \n ▪ ︎   A d d   c u m i n   s e e d s   a n d   l e t   i t   s i z z l e . O n c e   t h e   c u m i n   s e e d s   h a v e   s i z z l e d ,   a d d   o n i o n s   a n d   s a u t e   t h e m   t i l l   i t   t u r n s   g o l d e n   b r o w n   i n   c o l o r . A d d   t h e   k a r e l a ,   r e d   c h i l l i   p o w d e r ,   a m c h u r   p o w d e r ,   c o r i a n d e r   p o w d e r   a n d   b e s a n . \n ▪ ︎   S t i r   t o   c o m b i n e   t h e   m a s a l a s   i n t o   t h e   k a r e l a . D r i z z l e   a   l i t t l e   e x t r a   o i l   o n   t h e   t o p   a n d   m i x   a g a i n . \n ▪ ︎   C o v e r   t h e   p a n   a n d   s i m m e r   M a s a l a   K a r e l a   s t i r r i n g   o c c a s i o n a l l y   u n t i l   e v e r y t h i n g   c o m e s   t o g e t h e r   w e l l . \n ▪ ︎   T u r n   o f f   t h e   h e a t . T r a n s f e r   M a s a l a   K a r e l a   i n t o   a   s e r v i n g   b o w l   a n d   s e r v e . S e r v e   M a s a l a   K a r e l a   a l o n g   w i t h   P a n c h m e l   D a l   a n d   P h u l k a   f o r   a   w e e k d a y   m e a l   w i t h   y o u r   f a m i l y . \n \n 🌐   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / m a s a l a - k a r e l a - r e c i p e \n \n 🍔 \n \n •   s a l t \n •   a m c h u r   ( d r y   m a n g o   p o w d e r ) \n •   k a r e l a   ( b i t t e r   g o u r d   p a v a k k a i ) \n •   r e d   c h i l l i   p o w d e r \n •   g r a m   f l o u r   ( b e s a n ) \n •   o n i o n \n •   c u m i n   s e e d s   ( j e e r a ) \n •   c o r i a n d e r   p o w d e r \n •   t u r m e r i c   p o w d e r \n •   s u n f l o w e r   o i l \n \n 📷   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / i m a g e s / a r c h a n a s k i t c h e n / 1 - A u t h o r / P o o j a _ T h a k u r / K a r e l a _ M a s a l a _ R e c i p e - 4 _ 1 6 0 0 . j p g \n \n 🥗   1 0 \n\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1681329974769
        }
      },
      "id": "f08f4612"
    },
    {
      "cell_type": "code",
      "source": [
        "for recipe_index, recipe in enumerate(dataset_vectorized[:10]):\n",
        "    print('Recipe #{} length: {}'.format(recipe_index + 1, len(recipe)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Recipe #1 length: 1721\nRecipe #2 length: 1422\nRecipe #3 length: 1885\nRecipe #4 length: 2682\nRecipe #5 length: 1418\nRecipe #6 length: 2033\nRecipe #7 length: 2217\nRecipe #8 length: 1944\nRecipe #9 length: 1661\nRecipe #10 length: 1629\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1681329975723
        }
      },
      "id": "c1de035c"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_vectorized_padded_without_stops = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    dataset_vectorized,\n",
        "    padding='post',\n",
        "    truncating='post',\n",
        "    # We use -1 here and +1 in the next step to make sure\n",
        "    # that all recipes will have at least 1 stops sign at the end,\n",
        "    # since each sequence will be shifted and truncated afterwards\n",
        "    # (to generate X and Y sequences).\n",
        "    maxlen=MAX_RECIPE_LENGTH-1,\n",
        "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
        ")\n",
        "print(dataset_vectorized_padded_without_stops[0][:15])\n",
        "\n",
        "dataset_vectorized_padded = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    dataset_vectorized_padded_without_stops,\n",
        "    padding='post',\n",
        "    truncating='post',\n",
        "    maxlen=MAX_RECIPE_LENGTH+1,\n",
        "    value=tokenizer.texts_to_sequences([STOP_SIGN])[0]\n",
        ")\n",
        "print(dataset_vectorized_padded[0][:17])\n",
        "\n",
        "for recipe_index, recipe in enumerate(dataset_vectorized_padded[:10]):\n",
        "    print('Recipe #{} length: {}'.format(recipe_index, len(recipe)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[63  1 44  3  9  3 10  3  1 51  3  8  2 10  3]\n[63  1 44  3  9  3 10  3  1 51  3  8  2 10  3  1 37]\nRecipe #0 length: 5501\nRecipe #1 length: 5501\nRecipe #2 length: 5501\nRecipe #3 length: 5501\nRecipe #4 length: 5501\nRecipe #5 length: 5501\nRecipe #6 length: 5501\nRecipe #7 length: 5501\nRecipe #8 length: 5501\nRecipe #9 length: 5501\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1681329976639
        }
      },
      "id": "9216bd38"
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_sequence_to_string(dataset_vectorized_padded[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "📗   M a s a l a   K a r e l a   R e c i p e \n \n 🥕 \n \n •   1   t a b l e s p o o n   R e d   C h i l l i   p o w d e r \n •   3   t a b l e s p o o n   G r a m   f l o u r   ( b e s a n ) \n •   2   t e a s p o o n s   C u m i n   s e e d s   ( J e e r a ) \n •   1   t a b l e s p o o n   C o r i a n d e r   P o w d e r   ( D h a n i a ) \n •   2   t e a s p o o n s   T u r m e r i c   p o w d e r   ( H a l d i ) \n •   S a l t   -   t o   t a s t e \n •   1   t a b l e s p o o n   A m c h u r   ( D r y   M a n g o   P o w d e r ) \n •   6   K a r e l a   ( B i t t e r   G o u r d /   P a v a k k a i )   -   d e s e e d e d \n •   S u n f l o w e r   O i l   -   a s   r e q u i r e d \n •   1   O n i o n   -   t h i n l y   s l i c e d \n \n ⌛   4 5 \n \n 🍛   I n d i a n \n \n 📝 \n \n ▪ ︎   T o   b e g i n   m a k i n g   t h e   M a s a l a   K a r e l a   R e c i p e , d e - s e e d   t h e   k a r e l a   a n d   s l i c e . \n ▪ ︎   D o   n o t   r e m o v e   t h e   s k i n   a s   t h e   s k i n   h a s   a l l   t h e   n u t r i e n t s . \n ▪ ︎   A d d   t h e   k a r e l a   t o   t h e   p r e s s u r e   c o o k e r   w i t h   3   t a b l e s p o o n   o f   w a t e r ,   s a l t   a n d   t u r m e r i c   p o w d e r   a n d   p r e s s u r e   c o o k   f o r   t h r e e   w h i s t l e s . \n ▪ ︎   R e l e a s e   t h e   p r e s s u r e   i m m e d i a t e l y   a n d   o p e n   t h e   l i d s . \n ▪ ︎   K e e p   a s i d e . H e a t   o i l   i n   a   h e a v y   b o t t o m e d   p a n   o r   a   k a d h a i . \n ▪ ︎   A d d   c u m i n   s e e d s   a n d   l e t   i t   s i z z l e . O n c e   t h e   c u m i n   s e e d s   h a v e   s i z z l e d ,   a d d   o n i o n s   a n d   s a u t e   t h e m   t i l l   i t   t u r n s   g o l d e n   b r o w n   i n   c o l o r . A d d   t h e   k a r e l a ,   r e d   c h i l l i   p o w d e r ,   a m c h u r   p o w d e r ,   c o r i a n d e r   p o w d e r   a n d   b e s a n . \n ▪ ︎   S t i r   t o   c o m b i n e   t h e   m a s a l a s   i n t o   t h e   k a r e l a . D r i z z l e   a   l i t t l e   e x t r a   o i l   o n   t h e   t o p   a n d   m i x   a g a i n . \n ▪ ︎   C o v e r   t h e   p a n   a n d   s i m m e r   M a s a l a   K a r e l a   s t i r r i n g   o c c a s i o n a l l y   u n t i l   e v e r y t h i n g   c o m e s   t o g e t h e r   w e l l . \n ▪ ︎   T u r n   o f f   t h e   h e a t . T r a n s f e r   M a s a l a   K a r e l a   i n t o   a   s e r v i n g   b o w l   a n d   s e r v e . S e r v e   M a s a l a   K a r e l a   a l o n g   w i t h   P a n c h m e l   D a l   a n d   P h u l k a   f o r   a   w e e k d a y   m e a l   w i t h   y o u r   f a m i l y . \n \n 🌐   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / m a s a l a - k a r e l a - r e c i p e \n \n 🍔 \n \n •   s a l t \n •   a m c h u r   ( d r y   m a n g o   p o w d e r ) \n •   k a r e l a   ( b i t t e r   g o u r d   p a v a k k a i ) \n •   r e d   c h i l l i   p o w d e r \n •   g r a m   f l o u r   ( b e s a n ) \n •   o n i o n \n •   c u m i n   s e e d s   ( j e e r a ) \n •   c o r i a n d e r   p o w d e r \n •   t u r m e r i c   p o w d e r \n •   s u n f l o w e r   o i l \n \n 📷   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / i m a g e s / a r c h a n a s k i t c h e n / 1 - A u t h o r / P o o j a _ T h a k u r / K a r e l a _ M a s a l a _ R e c i p e - 4 _ 1 6 0 0 . j p g \n \n 🥗   1 0 \n ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1681329977556
        }
      },
      "id": "593da31a"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(dataset_vectorized_padded)\n",
        "\n",
        "print(dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<TensorSliceDataset element_spec=TensorSpec(shape=(5501,), dtype=tf.int32, name=None)>\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1681329978453
        }
      },
      "id": "1ac4e954"
    },
    {
      "cell_type": "code",
      "source": [
        "for recipe in dataset.take(1):\n",
        "    print('Raw recipe:\\n', recipe.numpy(), '\\n\\n\\n')\n",
        "    print('Stringified recipe:\\n')\n",
        "    recipe_sequence_to_string(recipe.numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Raw recipe:\n [ 63   1  44 ... 133 133 133] \n\n\n\nStringified recipe:\n\n📗   M a s a l a   K a r e l a   R e c i p e \n \n 🥕 \n \n •   1   t a b l e s p o o n   R e d   C h i l l i   p o w d e r \n •   3   t a b l e s p o o n   G r a m   f l o u r   ( b e s a n ) \n •   2   t e a s p o o n s   C u m i n   s e e d s   ( J e e r a ) \n •   1   t a b l e s p o o n   C o r i a n d e r   P o w d e r   ( D h a n i a ) \n •   2   t e a s p o o n s   T u r m e r i c   p o w d e r   ( H a l d i ) \n •   S a l t   -   t o   t a s t e \n •   1   t a b l e s p o o n   A m c h u r   ( D r y   M a n g o   P o w d e r ) \n •   6   K a r e l a   ( B i t t e r   G o u r d /   P a v a k k a i )   -   d e s e e d e d \n •   S u n f l o w e r   O i l   -   a s   r e q u i r e d \n •   1   O n i o n   -   t h i n l y   s l i c e d \n \n ⌛   4 5 \n \n 🍛   I n d i a n \n \n 📝 \n \n ▪ ︎   T o   b e g i n   m a k i n g   t h e   M a s a l a   K a r e l a   R e c i p e , d e - s e e d   t h e   k a r e l a   a n d   s l i c e . \n ▪ ︎   D o   n o t   r e m o v e   t h e   s k i n   a s   t h e   s k i n   h a s   a l l   t h e   n u t r i e n t s . \n ▪ ︎   A d d   t h e   k a r e l a   t o   t h e   p r e s s u r e   c o o k e r   w i t h   3   t a b l e s p o o n   o f   w a t e r ,   s a l t   a n d   t u r m e r i c   p o w d e r   a n d   p r e s s u r e   c o o k   f o r   t h r e e   w h i s t l e s . \n ▪ ︎   R e l e a s e   t h e   p r e s s u r e   i m m e d i a t e l y   a n d   o p e n   t h e   l i d s . \n ▪ ︎   K e e p   a s i d e . H e a t   o i l   i n   a   h e a v y   b o t t o m e d   p a n   o r   a   k a d h a i . \n ▪ ︎   A d d   c u m i n   s e e d s   a n d   l e t   i t   s i z z l e . O n c e   t h e   c u m i n   s e e d s   h a v e   s i z z l e d ,   a d d   o n i o n s   a n d   s a u t e   t h e m   t i l l   i t   t u r n s   g o l d e n   b r o w n   i n   c o l o r . A d d   t h e   k a r e l a ,   r e d   c h i l l i   p o w d e r ,   a m c h u r   p o w d e r ,   c o r i a n d e r   p o w d e r   a n d   b e s a n . \n ▪ ︎   S t i r   t o   c o m b i n e   t h e   m a s a l a s   i n t o   t h e   k a r e l a . D r i z z l e   a   l i t t l e   e x t r a   o i l   o n   t h e   t o p   a n d   m i x   a g a i n . \n ▪ ︎   C o v e r   t h e   p a n   a n d   s i m m e r   M a s a l a   K a r e l a   s t i r r i n g   o c c a s i o n a l l y   u n t i l   e v e r y t h i n g   c o m e s   t o g e t h e r   w e l l . \n ▪ ︎   T u r n   o f f   t h e   h e a t . T r a n s f e r   M a s a l a   K a r e l a   i n t o   a   s e r v i n g   b o w l   a n d   s e r v e . S e r v e   M a s a l a   K a r e l a   a l o n g   w i t h   P a n c h m e l   D a l   a n d   P h u l k a   f o r   a   w e e k d a y   m e a l   w i t h   y o u r   f a m i l y . \n \n 🌐   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / m a s a l a - k a r e l a - r e c i p e \n \n 🍔 \n \n •   s a l t \n •   a m c h u r   ( d r y   m a n g o   p o w d e r ) \n •   k a r e l a   ( b i t t e r   g o u r d   p a v a k k a i ) \n •   r e d   c h i l l i   p o w d e r \n •   g r a m   f l o u r   ( b e s a n ) \n •   o n i o n \n •   c u m i n   s e e d s   ( j e e r a ) \n •   c o r i a n d e r   p o w d e r \n •   t u r m e r i c   p o w d e r \n •   s u n f l o w e r   o i l \n \n 📷   h t t p s : / / w w w . a r c h a n a s k i t c h e n . c o m / i m a g e s / a r c h a n a s k i t c h e n / 1 - A u t h o r / P o o j a _ T h a k u r / K a r e l a _ M a s a l a _ R e c i p e - 4 _ 1 6 0 0 . j p g \n \n 🥗   1 0 \n ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣ ␣\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1681329979320
        }
      },
      "id": "c7662864"
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(recipe):\n",
        "    input_text = recipe[:-1]\n",
        "    target_text = recipe[1:]\n",
        "    \n",
        "    return input_text, target_text\n",
        "\n",
        "dataset_targeted = dataset.map(split_input_target)\n",
        "\n",
        "print(dataset_targeted)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<MapDataset element_spec=(TensorSpec(shape=(5500,), dtype=tf.int32, name=None), TensorSpec(shape=(5500,), dtype=tf.int32, name=None))>\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1681329980423
        }
      },
      "id": "bd3cd075"
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset_targeted.take(1):\n",
        "    print('Input sequence size:', repr(len(input_example.numpy())))\n",
        "    print('Target sequence size:', repr(len(target_example.numpy())))\n",
        "    print()\n",
        "    \n",
        "    input_stringified = tokenizer.sequences_to_texts([input_example.numpy()[:50]])[0]\n",
        "    target_stringified = tokenizer.sequences_to_texts([target_example.numpy()[:50]])[0]\n",
        "    \n",
        "    print('Input:  ', repr(''.join(input_stringified)))\n",
        "    print('Target: ', repr(''.join(target_stringified))) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Input sequence size: 5500\nTarget sequence size: 5500\n\nInput:   '📗   M a s a l a   K a r e l a   R e c i p e \\n \\n 🥕 \\n \\n •   1   t a b l e s p o o n   R e d   C h i l'\nTarget:  '  M a s a l a   K a r e l a   R e c i p e \\n \\n 🥕 \\n \\n •   1   t a b l e s p o o n   R e d   C h i l l'\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1681329981321
        }
      },
      "id": "f0d4cae1"
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:10], target_example[:10])):\n",
        "    print('Step {:2d}'.format(i + 1))\n",
        "    print('  input: {} ({:s})'.format(input_idx, repr(tokenizer.sequences_to_texts([[input_idx.numpy()]])[0])))\n",
        "    print('  expected output: {} ({:s})'.format(target_idx, repr(tokenizer.sequences_to_texts([[target_idx.numpy()]])[0])))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Step  1\n  input: 63 ('📗')\n  expected output: 1 (' ')\nStep  2\n  input: 1 (' ')\n  expected output: 44 ('M')\nStep  3\n  input: 44 ('M')\n  expected output: 3 ('a')\nStep  4\n  input: 3 ('a')\n  expected output: 9 ('s')\nStep  5\n  input: 9 ('s')\n  expected output: 3 ('a')\nStep  6\n  input: 3 ('a')\n  expected output: 10 ('l')\nStep  7\n  input: 10 ('l')\n  expected output: 3 ('a')\nStep  8\n  input: 3 ('a')\n  expected output: 1 (' ')\nStep  9\n  input: 1 (' ')\n  expected output: 51 ('K')\nStep 10\n  input: 51 ('K')\n  expected output: 3 ('a')\n"
        }
      ],
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1681329982201
        }
      },
      "id": "25fa31c5"
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_targeted)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<MapDataset element_spec=(TensorSpec(shape=(5500,), dtype=tf.int32, name=None), TensorSpec(shape=(5500,), dtype=tf.int32, name=None))>\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1681329983133
        }
      },
      "id": "29611c95"
    },
    {
      "cell_type": "code",
      "source": [
        "print('TOTAL_RECIPES_NUM: ', TOTAL_RECIPES_NUM)\n",
        "print('MAX_RECIPE_LENGTH: ', MAX_RECIPE_LENGTH)\n",
        "print('VOCABULARY_SIZE: ', VOCABULARY_SIZE)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "TOTAL_RECIPES_NUM:  5934\nMAX_RECIPE_LENGTH:  5500\nVOCABULARY_SIZE:  154\n"
        }
      ],
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1681329983956
        }
      },
      "id": "b9e19e04"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Batch size.\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Buffer size to shuffle the dataset (TF data is designed to work\n",
        "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in\n",
        "# which it shuffles elements).\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "dataset_train = dataset_targeted.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat() \n",
        "  # \\\n",
        "  # Shuffling examples first. \\\n",
        "  # Splitting examples on batches. \\\n",
        "  # Making a dataset to be repeatable (it will never ends). \n",
        "  \n",
        "\n",
        "print(dataset_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<RepeatDataset element_spec=(TensorSpec(shape=(16, 5500), dtype=tf.int32, name=None), TensorSpec(shape=(16, 5500), dtype=tf.int32, name=None))>\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1681329984812
        }
      },
      "id": "09e1a3f4"
    },
    {
      "cell_type": "code",
      "source": [
        "for input_text, target_text in dataset_train.take(1):\n",
        "    print('1st batch: input_text:', input_text)\n",
        "    print()\n",
        "    print('1st batch: target_text:', target_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1st batch: input_text: tf.Tensor(\n[[ 63   1  34 ... 133 133 133]\n [ 63   1  31 ... 133 133 133]\n [ 63   1  80 ... 133 133 133]\n ...\n [ 63   1  40 ... 133 133 133]\n [ 63   1  37 ... 133 133 133]\n [ 63   1  34 ... 133 133 133]], shape=(16, 5500), dtype=int32)\n\n1st batch: target_text: tf.Tensor(\n[[  1  34  11 ... 133 133 133]\n [  1  31  15 ... 133 133 133]\n [  1  80  12 ... 133 133 133]\n ...\n [  1  40   2 ... 133 133 133]\n [  1  37   5 ... 133 133 133]\n [  1  34  11 ... 133 133 133]], shape=(16, 5500), dtype=int32)\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1681329985726
        }
      },
      "id": "d97006fb"
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_vocab_size = 10\n",
        "tmp_embedding_size = 5\n",
        "tmp_input_length = 8\n",
        "tmp_batch_size = 2\n",
        "\n",
        "tmp_model = tf.keras.models.Sequential()\n",
        "tmp_model.add(tf.keras.layers.Embedding(\n",
        "  input_dim=tmp_vocab_size,\n",
        "  output_dim=tmp_embedding_size,\n",
        "  input_length=tmp_input_length\n",
        "))\n",
        "# The model will take as input an integer matrix of size (batch, input_length).\n",
        "# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\n",
        "# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
        "tmp_input_array = np.random.randint(\n",
        "  low=0,\n",
        "  high=tmp_vocab_size,\n",
        "  size=(tmp_batch_size, tmp_input_length)\n",
        ")\n",
        "tmp_model.compile('rmsprop', 'mse')\n",
        "tmp_output_array = tmp_model.predict(tmp_input_array)\n",
        "\n",
        "print('tmp_input_array shape:', tmp_input_array.shape)\n",
        "print('tmp_input_array:')\n",
        "print(tmp_input_array)\n",
        "print()\n",
        "print('tmp_output_array shape:', tmp_output_array.shape)\n",
        "print('tmp_output_array:')\n",
        "print(tmp_output_array)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 61ms/step\ntmp_input_array shape: (2, 8)\ntmp_input_array:\n[[2 4 5 7 8 6 5 5]\n [5 4 5 4 0 6 1 6]]\n\ntmp_output_array shape: (2, 8, 5)\ntmp_output_array:\n[[[-0.0465762   0.02893068  0.04156489 -0.04801992 -0.00650096]\n  [-0.01114875  0.0124165   0.02126211 -0.03550124  0.03258998]\n  [ 0.01953992 -0.03842988 -0.04963877  0.03643965  0.02574452]\n  [ 0.01737254  0.03647811  0.04181746 -0.01024995 -0.0451902 ]\n  [-0.00797472  0.01435146 -0.04461931  0.02003052  0.02440539]\n  [-0.03171824  0.03415085  0.04318965 -0.00399424 -0.02049167]\n  [ 0.01953992 -0.03842988 -0.04963877  0.03643965  0.02574452]\n  [ 0.01953992 -0.03842988 -0.04963877  0.03643965  0.02574452]]\n\n [[ 0.01953992 -0.03842988 -0.04963877  0.03643965  0.02574452]\n  [-0.01114875  0.0124165   0.02126211 -0.03550124  0.03258998]\n  [ 0.01953992 -0.03842988 -0.04963877  0.03643965  0.02574452]\n  [-0.01114875  0.0124165   0.02126211 -0.03550124  0.03258998]\n  [ 0.00617354 -0.02050952 -0.02704324  0.04760363  0.04603554]\n  [-0.03171824  0.03415085  0.04318965 -0.00399424 -0.02049167]\n  [-0.00351813  0.03653042  0.03938596 -0.02201257  0.02699972]\n  [-0.03171824  0.03415085  0.04318965 -0.00399424 -0.02049167]]]\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1681329986786
        }
      },
      "id": "a997aab4"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        batch_input_shape=[batch_size, None]\n",
        "    ))\n",
        "\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        units=rnn_units,\n",
        "        return_sequences=True,\n",
        "        stateful=True,\n",
        "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
        "    ))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(vocab_size))\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "  vocab_size=VOCABULARY_SIZE,\n",
        "  embedding_dim=256,\n",
        "  rnn_units=1024,\n",
        "  batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_1 (Embedding)     (16, None, 256)           39424     \n                                                                 \n lstm (LSTM)                 (16, None, 1024)          5246976   \n                                                                 \n dense (Dense)               (16, None, 154)           157850    \n                                                                 \n=================================================================\nTotal params: 5,444,250\nTrainable params: 5,444,250\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1681329987882
        }
      },
      "id": "4798a269"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydot"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pydot in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (1.4.2)\r\nRequirement already satisfied: pyparsing>=2.1.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pydot) (3.0.9)\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1681329989630
        }
      },
      "id": "927c88f4"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install graphviz"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: graphviz in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.20.1)\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1681329991044
        }
      },
      "id": "394d1174"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    show_shapes=True,\n",
        "    show_layer_names=True,\n",
        "    to_file='model.png'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1681329991611
        }
      },
      "id": "955c6400"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for input_example_batch, target_example_batch in dataset_train.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "     "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(16, 5500, 154) # (batch_size, sequence_length, vocab_size)\n"
        }
      ],
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1681330002072
        }
      },
      "id": "90285265"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
        "print(example_batch_predictions[0, 0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prediction for the 1st letter of the batch 1st sequense:\ntf.Tensor(\n[-4.8817694e-03  1.9801507e-04 -1.5280609e-03 -2.3191678e-03\n  6.8645757e-03  7.6462823e-04  1.6103250e-03 -1.4124127e-03\n  5.6006173e-03 -4.3630265e-03 -2.4929435e-03 -3.6169435e-03\n -5.5917527e-04  1.6152102e-03 -1.8562538e-03  3.7493207e-04\n  7.2407932e-04 -6.4716330e-03  3.8224773e-04  3.5385289e-03\n  1.3478119e-03 -8.9375116e-04 -2.0827923e-03  1.7523407e-03\n -1.8584195e-03 -1.1441391e-03 -3.4636715e-03  7.4369385e-04\n -1.4835250e-03  3.6288607e-03  4.9392455e-03  6.3400487e-03\n -6.7830575e-04  2.8785407e-03  4.9898443e-03 -3.4335733e-03\n -1.0825689e-03  4.4813403e-03 -3.7201345e-03  6.4033305e-04\n  5.3127692e-04 -8.7838189e-04 -3.5548555e-03  1.4114352e-03\n  4.2325351e-03  9.5654791e-04 -1.4608077e-03 -4.8447656e-04\n -6.9947606e-03  6.1383704e-04  2.1433027e-03  3.4971372e-03\n -2.7298713e-03  1.1203984e-03  1.5544466e-03 -2.0658784e-04\n -4.1725296e-03  6.4437860e-04 -1.8412692e-03 -3.8350616e-03\n  2.7504964e-03  6.0188426e-03  7.1474118e-04 -2.5754313e-03\n  3.2940349e-03 -2.5591434e-03 -2.4868164e-04 -7.6886022e-04\n  2.6316815e-03 -3.5493192e-03  2.3145848e-03 -2.3396888e-03\n -2.5796142e-04  6.3237909e-04  4.6394179e-03 -4.5994129e-03\n  2.4227821e-03  1.0473507e-03  6.0628569e-03  3.5366325e-03\n  3.0590093e-03  7.0412440e-05  3.5224720e-03 -7.7691884e-04\n -1.1763141e-03 -2.4657259e-03 -5.3886417e-04  1.0500769e-03\n -3.0455943e-03  2.2994883e-03  2.4489101e-03  7.4071479e-03\n -3.6490089e-03 -9.8838401e-04 -4.9736854e-03 -1.7929745e-03\n -5.4669511e-03  2.0449944e-03  8.6322922e-04  2.5409344e-03\n  8.3415827e-04 -3.5616891e-03 -1.6049715e-03 -6.9893361e-04\n  3.1937526e-03 -1.7397365e-04  3.5325605e-03  1.4969546e-03\n -3.5881028e-03  3.3209340e-03 -3.3036503e-03  3.5419115e-03\n -7.1075647e-03  8.0410892e-04  4.9986434e-03  9.3523297e-04\n -1.8234700e-03 -1.0302402e-03  2.8736203e-03  3.9845207e-03\n -1.8392815e-03 -3.6826008e-04 -4.7257855e-03  2.8351799e-04\n  2.2588721e-03  6.1362218e-03 -1.4832693e-03 -3.2936074e-03\n  2.8024178e-03 -4.5109270e-03 -1.7151068e-04 -1.2529409e-04\n  1.7361364e-03 -4.2887125e-03  4.4549145e-03 -6.5866916e-04\n  2.3219048e-03  3.1388700e-03  9.5113809e-04 -4.1139666e-03\n  4.1026194e-03 -1.6497750e-03  2.6170560e-03 -4.1231206e-03\n -2.1337522e-03 -1.4196481e-03  4.5256834e-03  1.0925287e-05\n  2.3037463e-03  8.5751116e-03  8.8587515e-03  5.5141859e-03\n -2.4379990e-03  7.3728152e-04], shape=(154,), dtype=float32)\n"
        }
      ],
      "execution_count": 50,
      "metadata": {
        "gather": {
          "logged": 1681330002841
        }
      },
      "id": "0620622e"
    },
    {
      "cell_type": "code",
      "source": [
        "# logits is 2-D Tensor with shape [batch_size, num_classes].\n",
        "# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n",
        "# In the example below we say that the probability for class \"0\"\n",
        "# (element with index 0) is low but the probability for class \"2\" is much higher.\n",
        "tmp_logits = [\n",
        "  [-0.95, 0, 0.95],\n",
        "];\n",
        "\n",
        "# Let's generate 5 samples. Each sample is a class index. Class probabilities \n",
        "# are being taken into account (we expect to see more samples of class \"2\").\n",
        "tmp_samples = tf.random.categorical(\n",
        "    logits=tmp_logits,\n",
        "    num_samples=5\n",
        ")\n",
        "\n",
        "print(tmp_samples)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "tf.Tensor([[1 2 1 1 0]], shape=(1, 5), dtype=int64)\n"
        }
      ],
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1681330003404
        }
      },
      "id": "6e651c6a"
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(\n",
        "    logits=example_batch_predictions[0],\n",
        "    num_samples=1\n",
        ")\n",
        "\n",
        "sampled_indices = tf.squeeze(\n",
        "    input=sampled_indices,\n",
        "    axis=-1\n",
        ").numpy()\n",
        "\n",
        "sampled_indices.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "(5500,)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1681330003965
        }
      },
      "id": "952534c8"
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices[:100]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "array([149,  36,  34, 146,  24,  72,  28,  14,  30, 152,  47,  36, 140,\n        57,  85,  73, 153,   0,  94,  84, 137, 111,  29,  40, 138,  44,\n         1,  32,  44, 117,  81,  67, 115,  25,  45, 149, 120,  33, 129,\n       112, 136,  20,  21, 111,  38,  15, 145,  72, 135,  43, 132,  91,\n       152,  57, 130,  45,  51,  97,  68, 131,  25,  66,  62, 146, 123,\n        39,  62,  29,  38,  96,  46,  59, 109, 142,  58,  79,   3, 117,\n        14,   6, 127,   4,  46, 108, 151,  54, 147,  33,  33, 106,  67,\n        77,   2, 144,  30,   9,  19, 109,   4,  27])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "gather": {
          "logged": 1681330004543
        }
      },
      "id": "615b48c7"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Input:\\n', repr(''.join(tokenizer.sequences_to_texts([input_example_batch[0].numpy()[:50]]))))\n",
        "print()\n",
        "print('Next char prediction:\\n', repr(''.join(tokenizer.sequences_to_texts([sampled_indices[:50]]))))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Input:\n '📗   R o a s t e d   C a u l i f l o w e r   R e c i p e \\n \\n 🥕 \\n \\n •   3   t a b l e s p o o n   E x'\n\nNext char prediction:\n \"⅔ ) C ं b E v \\n , } G ) ड़ z é V ℃ \\ufeff ' \\u2009 α 1 P × M   ▪ M ˚ 7 📝 ` y B ⅔ υ ︎ ⅓ Æ \\u200b • k α _ p ी E — j\"\n"
        }
      ],
      "execution_count": 54,
      "metadata": {
        "gather": {
          "logged": 1681330005070
        }
      },
      "id": "01571b4c"
    },
    {
      "cell_type": "code",
      "source": [
        "# An objective function.\n",
        "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
        "def loss(labels, logits):\n",
        "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "      y_true=labels,\n",
        "      y_pred=logits,\n",
        "      from_logits=True\n",
        "    )\n",
        "    \n",
        "    return entropy\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss.shape:      \", example_batch_loss.shape)\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean()) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prediction shape:  (16, 5500, 154)  # (batch_size, sequence_length, vocab_size)\nscalar_loss.shape:       (16, 5500)\nscalar_loss:       5.0503693\n"
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1681330005667
        }
      },
      "id": "690a53ef"
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='sparse_categorical_crossentropy'\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1681330006274
        }
      },
      "id": "026a463e"
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=5,\n",
        "    monitor='loss',\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1681330006853
        }
      },
      "id": "c51f5dcf"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a checkpoints directory.\n",
        "checkpoint_dir = 'tmp/checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 58,
      "metadata": {
        "gather": {
          "logged": 1681330007402
        }
      },
      "id": "07b88ee1"
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_callback = tf.keras.callbacks.ModelCheckpoint(\"Model.h5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=50)"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "gather": {
          "logged": 1681330007970
        }
      },
      "id": "32860fd3"
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 7\n",
        "INITIAL_EPOCH = 1\n",
        "STEPS_PER_EPOCH = 50\n",
        "\n",
        "print('EPOCHS:          ', EPOCHS)\n",
        "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
        "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "EPOCHS:           7\nINITIAL_EPOCH:    1\nSTEPS_PER_EPOCH:  50\n"
        }
      ],
      "execution_count": 60,
      "metadata": {
        "gather": {
          "logged": 1681330008504
        }
      },
      "id": "827c2dc9"
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x=dataset_train,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    initial_epoch=INITIAL_EPOCH,\n",
        "    callbacks=[\n",
        "        checkpoint_callback,\n",
        "        early_stopping_callback,\n",
        "        save_model_callback\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Saving the trained model to file (to be able to re-use it later).\n",
        "model_name = 'recipe_generation_rnn_raw.h5'\n",
        "model.save(model_name, save_format='h5')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 2/7\n49/50 [============================>.] - ETA: 23s - loss: 2.1300 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: loss improved from inf to 2.11315, saving model to Model.h5\n50/50 [==============================] - 1200s 24s/step - loss: 2.1132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/7\n49/50 [============================>.] - ETA: 23s - loss: 1.2968 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: loss improved from 2.11315 to 1.29489, saving model to Model.h5\n50/50 [==============================] - 1182s 24s/step - loss: 1.2949\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/7\n49/50 [============================>.] - ETA: 23s - loss: 1.1965 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: loss improved from 1.29489 to 1.19415, saving model to Model.h5\n50/50 [==============================] - 1159s 23s/step - loss: 1.1941\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/7\n49/50 [============================>.] - ETA: 23s - loss: 1.1180 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: loss improved from 1.19415 to 1.12360, saving model to Model.h5\n50/50 [==============================] - 1165s 23s/step - loss: 1.1236\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/7\n49/50 [============================>.] - ETA: 23s - loss: 1.1638 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: loss did not improve from 1.12360\n50/50 [==============================] - 1169s 23s/step - loss: 1.1642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/7\n49/50 [============================>.] - ETA: 23s - loss: 1.0421 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: loss improved from 1.12360 to 1.04725, saving model to Model.h5\n50/50 [==============================] - 1154s 23s/step - loss: 1.0473\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "gather": {
          "logged": 1681337031971
        }
      },
      "id": "272a848c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}